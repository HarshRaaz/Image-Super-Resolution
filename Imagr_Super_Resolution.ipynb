{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imagr Super Resolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsqHxT8akn5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M050ZMokv94",
        "colab_type": "text"
      },
      "source": [
        "Image Super Resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqs9f23jk0tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input, regularizers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Add, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in54argWlBN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_images = glob.glob('lfw/lfw/**/*.jpg') #returns path of images\n",
        "print(len(face_images)) #contains 13243 images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsLUDmaUlIuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool\n",
        "progress = tqdm(total= len(face_images), position=0)\n",
        "def read(path):\n",
        "  img = image.load_img(path, target_size=(80,80,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255.\n",
        "  progress.update(1)\n",
        "  return img\n",
        "p = Pool(10)\n",
        "img_array = p.map(read, face_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjx7CTJalR6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('img_array.pickle','wb') as f:\n",
        "  pickle.dump(img_array, f)\n",
        "print(len(img_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RylVrqnYlXae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_images = np.array(img_array)\n",
        "#Split test and train data. all_images will be our output images\n",
        "train_x, val_x = train_test_split(all_images, random_state = 32, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POuiTX62lblz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we will make input images by lowering resolution without changing the size\n",
        "def pixalate_image(image, scale_percent = 40):\n",
        "  width = int(image.shape[1] * scale_percent / 100)\n",
        "  height = int(image.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "  small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "  \n",
        "  # scale back to original size\n",
        "  width = int(small_image.shape[1] * 100 / scale_percent)\n",
        "  height = int(small_image.shape[0] * 100 / scale_percent)\n",
        "  dim = (width, height)\n",
        "  low_res_image = cv2.resize(small_image, dim, interpolation =  cv2.INTER_AREA)\n",
        " return low_res_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hupCEbZ0lh4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_px = []\n",
        "for i in range(train_x.shape[0]):\n",
        "  temp = pixalate_image(train_x[i,:,:,:])\n",
        "  train_x_px.append(temp)\n",
        "train_x_px = np.array(train_x_px)   #Distorted images\n",
        "# get low resolution images for the validation set\n",
        "val_x_px = []\n",
        "for i in range(val_x.shape[0]):\n",
        "  temp = pixalate_image(val_x[i,:,:,:])\n",
        "  val_x_px.append(temp)\n",
        "val_x_px = np.array(val_x_px)     #Distorted images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqYh2bAFlsuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input_img = Input(shape=(80, 80, 3))  \n",
        "    \n",
        "#encoding architecture\n",
        "x1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(Input_img)\n",
        "x2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x1)\n",
        "x3 = MaxPool2D(padding='same')(x2)\n",
        "x4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x3)\n",
        "x5 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x4)\n",
        "x6 = MaxPool2D(padding='same')(x5)\n",
        "encoded = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x6)\n",
        "#encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
        "# decoding architecture\n",
        "x7 = UpSampling2D()(encoded)\n",
        "x8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x7)\n",
        "x9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x8)\n",
        "x10 = Add()([x5, x9])\n",
        "x11 = UpSampling2D()(x10)\n",
        "x12 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x11)\n",
        "x13 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x12)\n",
        "x14 = Add()([x2, x13])\n",
        "# x3 = UpSampling2D((2, 2))(x3)\n",
        "# x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x3)\n",
        "# x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(x2)\n",
        "decoded = Conv2D(3, (3, 3), padding='same',activation='relu', kernel_regularizer=regularizers.l1(10e-10))(x14)\n",
        "autoencoder = Model(Input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0la1uFlujU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJiEj0Pclzwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=50, verbose=1, mode='min')\n",
        "model_checkpoint =  ModelCheckpoint('superResolution_checkpoint3.h5', save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzeowa-0l4cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = autoencoder.fit(train_x_px,train_x,\n",
        "            epochs=500,\n",
        "            validation_data=(val_x_px, val_x),\n",
        "            callbacks=[early_stopper, model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYDke7Cl8N5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = autoencoder.evaluate(val_x_px, val_x)\n",
        "print('val_loss, val_accuracy', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7yWfBXqmAhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = autoencoder.predict(val_x_px)\n",
        "n = 4\n",
        "plt.figure(figsize= (20,10))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(3, n, i+1)\n",
        "  plt.imshow(val_x_px[i+20])\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = plt.subplot(3, n, i+1+n)\n",
        "  plt.imshow(predictions[i+20])\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRVlBDOcmGXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}